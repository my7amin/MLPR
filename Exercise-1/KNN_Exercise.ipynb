{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Let's get started"
      ],
      "metadata": {
        "id": "hdVdq8qi2PVn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Import required python libraries"
      ],
      "metadata": {
        "id": "bhGiDMwhAF94"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.neighbors import DistanceMetric\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "pd.set_option('display.max_rows', 200)\n",
        "pd.set_option('display.max_columns', 50)\n",
        "pd.set_option('display.width', 1080)"
      ],
      "metadata": {
        "id": "4t_n7C8pM7GW"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Create and fill the feature vector\n",
        "\n"
      ],
      "metadata": {
        "id": "4bvyECSq1kJV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a feature vector with columns representing alphabets\n",
        "#alphabets = 'ابپتثجچحخدذرزژسشصضطظعغفقکگلمنوهی'\n",
        "#alphabets = 'ابپتثجچحخدذرزژسشصضطظعغفقکكگلمنوهیيئءأإآة'\n",
        "alphabets = 'پچژكگیيئءأإآة'\n",
        "feature_vector = pd.DataFrame(0, index=pd.RangeIndex(start=1, stop=2), columns=list(reversed(alphabets)))\n",
        "\n",
        "# Read the Excel file into a DataFrame\n",
        "xlsx_file_path = 'dataset-1.xlsx'\n",
        "main_df = pd.read_excel(xlsx_file_path)\n",
        "labels = main_df.iloc[:, 1]\n",
        "labels.index = labels.index + 1"
      ],
      "metadata": {
        "id": "sbmjLBK2N6bu"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Attention : Now you have to run only one of the feature vectors below every time that you want to calculate the predictions !!!"
      ],
      "metadata": {
        "id": "zvNTkZps0-tf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Creating the feature vector using the Binary BoW"
      ],
      "metadata": {
        "id": "IMDyj3WAPmTD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an empty matrix to store feature vectors for each row\n",
        "feature_matrix = pd.DataFrame(0, index=main_df.index, columns=list(alphabets))\n",
        "\n",
        "# Iterate through each row in the DataFrame\n",
        "for index, row in main_df.iterrows():\n",
        "    # Assume the first column contains sentences\n",
        "    sentence = str(row.iloc[0])\n",
        "\n",
        "    # Iterate through each column in the feature vector\n",
        "    for column in feature_vector.columns:\n",
        "        # Check if the character is present in the sentence\n",
        "        if column in sentence:\n",
        "            # If present, set the corresponding value in the feature matrix to 1\n",
        "            feature_matrix.at[index, column] = 1\n",
        "\n",
        "# Change the index to start from one instead of zero\n",
        "feature_matrix.index = feature_matrix.index + 1\n",
        "\n",
        "# Display the resulting feature matrix\n",
        "feature_matrix"
      ],
      "metadata": {
        "id": "ZGyW14psPm0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Creating the feature vector using Weighted BoW"
      ],
      "metadata": {
        "id": "uWLinZyvskBu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an empty matrix to store weighted feature vectors for each row\n",
        "feature_matrix = pd.DataFrame(0, index=main_df.index, columns=list(alphabets))\n",
        "\n",
        "# Iterate through each row in the DataFrame\n",
        "for index, row in main_df.iterrows():\n",
        "    # Assume the first column contains sentences\n",
        "    sentence = str(row.iloc[0])\n",
        "\n",
        "    # Iterate through each column in the feature vector\n",
        "    for column in feature_vector.columns:\n",
        "        # Count the occurrences of the character in the sentence\n",
        "        count = sentence.count(column)\n",
        "\n",
        "        # Set the corresponding value in the weighted feature matrix\n",
        "        feature_matrix.at[index, column] = count\n",
        "\n",
        "# Change the index to start from one instead of zero\n",
        "feature_matrix.index = feature_matrix.index + 1\n",
        "\n",
        "# Display the resulting weighted feature matrix\n",
        "print(feature_matrix)"
      ],
      "metadata": {
        "id": "ZhRhhw4lsm1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Creating the feature vector using Length Normalized Weighted BoW"
      ],
      "metadata": {
        "id": "x0ReYhTwyi63"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an empty matrix to store length normalized feature vectors for each row\n",
        "feature_matrix = pd.DataFrame(0, index=main_df.index, columns=list(alphabets))\n",
        "\n",
        "# Iterate through each row in the DataFrame\n",
        "for index, row in main_df.iterrows():\n",
        "    # Assume the first column contains sentences\n",
        "    sentence = str(row.iloc[0])\n",
        "\n",
        "    # Iterate through each column in the feature vector\n",
        "    for column in feature_vector.columns:\n",
        "        # Count the occurrences of the character in the sentence\n",
        "        count = sentence.count(column)\n",
        "\n",
        "        # Set the corresponding value in the normalized feature matrix\n",
        "        feature_matrix.at[index, column] = count / len(sentence)\n",
        "\n",
        "# Change the index to start from one instead of zero\n",
        "feature_matrix.index = feature_matrix.index + 1\n",
        "\n",
        "# Display the resulting normalized feature matrix\n",
        "print(feature_matrix)"
      ],
      "metadata": {
        "id": "UoUZ5NQTlImN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Creating the feature vector using Z-Score Normalized Weighted BoW"
      ],
      "metadata": {
        "id": "_LPd-MSi3FNH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an empty matrix to store Z-score normalized feature vectors for each row\n",
        "feature_matrix = pd.DataFrame(0, index=main_df.index, columns=list(alphabets))\n",
        "\n",
        "# Iterate through each row in the DataFrame\n",
        "for index, row in main_df.iterrows():\n",
        "    # Assume the first column contains sentences\n",
        "    sentence = str(row.iloc[0])\n",
        "\n",
        "    # Iterate through each column in the feature vector\n",
        "    for column in feature_vector.columns:\n",
        "        # Count the occurrences of the character in the sentence\n",
        "        count = sentence.count(column)\n",
        "\n",
        "        # Set the corresponding value in the feature matrix\n",
        "        feature_matrix.at[index, column] = count\n",
        "\n",
        "# Standardize the feature matrix using Z-score normalization\n",
        "scaler = StandardScaler()\n",
        "feature_matrix = pd.DataFrame(scaler.fit_transform(feature_matrix),\n",
        "                                                 index=feature_matrix.index,\n",
        "                                                 columns=feature_matrix.columns)\n",
        "\n",
        "# Change the index to start from one instead of zero\n",
        "feature_matrix.index = feature_matrix.index + 1\n",
        "\n",
        "# Display the resulting Z-score normalized feature matrix\n",
        "print(feature_matrix)\n"
      ],
      "metadata": {
        "id": "wnhmGnIE3Fuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Creating the feature vector using TF-IDF(Term Frequency-Inverse Document Frequency) transformation"
      ],
      "metadata": {
        "id": "qaShm8gLb1-G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an empty matrix to store TF-IDF transformed feature vectors for each row\n",
        "feature_matrix = pd.DataFrame(0, index=main_df.index, columns=list(alphabets))\n",
        "\n",
        "# Convert sentences into a list\n",
        "sentences = main_df.iloc[:, 0].astype(str).tolist()\n",
        "\n",
        "# Initialize the TF-IDF vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer(analyzer='char', vocabulary=list(alphabets))\n",
        "\n",
        "# Fit and transform the sentences using TF-IDF\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(sentences)\n",
        "\n",
        "# Fill the TF-IDF values into the feature matrix\n",
        "feature_matrix.loc[:, list(alphabets)] = tfidf_matrix.toarray()\n",
        "\n",
        "# Change the index to start from one instead of zero\n",
        "feature_matrix.index = feature_matrix.index + 1\n",
        "\n",
        "# Display the resulting TF-IDF transformed feature matrix\n",
        "print(feature_matrix)"
      ],
      "metadata": {
        "id": "8eZWKdhbboip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Now, We have to split data into Train data and Test data\n"
      ],
      "metadata": {
        "id": "HFmPnXdH2w_s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the number of rows in the DataFrame\n",
        "num_rows = feature_matrix.shape[0]\n",
        "\n",
        "# Define the condition for selecting test rows\n",
        "test_indices = [i for i in range(1, num_rows + 1) if i % 10 == 0]\n",
        "\n",
        "# Create the train and test DataFrames\n",
        "X_train = feature_matrix.drop(test_indices)\n",
        "y_train = labels.drop(test_indices)\n",
        "\n",
        "X_test  = feature_matrix.loc[test_indices]\n",
        "y_test  = labels.loc[test_indices]"
      ],
      "metadata": {
        "id": "Aoo2yVcp2-YK"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Using k-NN classifiers for k = 1, 3, 5 with Euclidean metric"
      ],
      "metadata": {
        "id": "c5wAmrb6kSn4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize k-NN classifiers for k = 1, 3, 5 with Euclidean metric\n",
        "for k in [1, 3, 5]:\n",
        "    knn_classifier = KNeighborsClassifier(n_neighbors=k, metric='euclidean')\n",
        "\n",
        "    # Fit the classifier on the training data\n",
        "    knn_classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Predict the labels for the test data\n",
        "    y_pred = knn_classifier.predict(X_test)\n",
        "\n",
        "    # Evaluate the accuracy\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    # Display the results\n",
        "    print(f\"\\nResults for k = {k} (Euclidean metric):\")\n",
        "    print(f\"Predicted Labels: {y_pred}\")\n",
        "    print(f\"True Labels     : {y_test.values}\")\n",
        "    print(f\"Accuracy: {accuracy:.2%}\")\n",
        "    print(f\"Error   : {1 - accuracy:.2%}\")"
      ],
      "metadata": {
        "id": "AMzBirKr7sGL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Using k-NN classifiers for k = 1, 3, 5 with Cosine metric"
      ],
      "metadata": {
        "id": "zuTV7r2okus5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zFLBk4aPfVT1"
      },
      "outputs": [],
      "source": [
        "# Initialize k-NN classifiers for k = 1, 3, 5 with Cosine metric\n",
        "for k in [1, 3, 5]:\n",
        "    knn_classifier = KNeighborsClassifier(n_neighbors=k, metric='cosine')\n",
        "\n",
        "    # Fit the classifier on the training data\n",
        "    knn_classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Predict the labels for the test data\n",
        "    y_pred = knn_classifier.predict(X_test)\n",
        "\n",
        "    # Evaluate the accuracy\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    # Display the results\n",
        "    print(f\"\\nResults for k = {k} (Cosine metric):\")\n",
        "    print(f\"Predicted Labels: {y_pred}\")\n",
        "    print(f\"True Labels     : {y_test.values}\")\n",
        "    print(f\"Accuracy: {accuracy:.2%}\")\n",
        "    print(f\"Error   : {1 - accuracy:.2%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Using k-NN classifiers for k = 1, 3, 5 with Correlation metric"
      ],
      "metadata": {
        "id": "nWgF0e-Rk4Ce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize k-NN classifiers for k = 1, 3 and 5 with Correlation metric\n",
        "for k in [1, 3, 5]:\n",
        "    knn_classifier = KNeighborsClassifier(n_neighbors=k, metric='correlation')\n",
        "\n",
        "    # Fit the classifier on the training data\n",
        "    knn_classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Predict the labels for the test data\n",
        "    y_pred = knn_classifier.predict(X_test)\n",
        "\n",
        "    # Evaluate the accuracy\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    # Display the results\n",
        "    print(f\"\\nResults for k = {k} (Correlation metric):\")\n",
        "    print(f\"Predicted Labels: {y_pred}\")\n",
        "    print(f\"True Labels     : {y_test.values}\")\n",
        "    print(f\"Accuracy: {accuracy:.2%}\")\n",
        "    print(f\"Error   : {1 - accuracy:.2%}\")"
      ],
      "metadata": {
        "id": "_YsTLjbtIA6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Using k-NN classifiers for k = 1, 3, 5 with Manhattan metric"
      ],
      "metadata": {
        "id": "q0HMhbl2aeQu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize k-NN classifiers for k = 1, 3 and 5 with Manhattan metric\n",
        "for k in [1, 3, 5]:\n",
        "    knn_classifier = KNeighborsClassifier(n_neighbors=k, metric='manhattan')\n",
        "\n",
        "    # Fit the classifier on the training data\n",
        "    knn_classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Predict the labels for the test data\n",
        "    y_pred = knn_classifier.predict(X_test)\n",
        "\n",
        "    # Evaluate the accuracy\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    # Display the results\n",
        "    print(f\"\\nResults for k = {k} (Manhattan metric):\")\n",
        "    print(f\"Predicted Labels: {y_pred}\")\n",
        "    print(f\"True Labels     : {y_test.values}\")\n",
        "    print(f\"Accuracy: {accuracy:.2%}\")\n",
        "    print(f\"Error   : {1 - accuracy:.2%}\")"
      ],
      "metadata": {
        "id": "8hNYBrcqah9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Using k-NN classifiers for k = 1, 3, 5 with Chebyshev metric"
      ],
      "metadata": {
        "id": "aVYTF7ELfQL4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize k-NN classifiers for k = 1, 3 and 5 with Chebyshev metric\n",
        "for k in [1, 3, 5]:\n",
        "    knn_classifier = KNeighborsClassifier(n_neighbors=k, metric='chebyshev')\n",
        "\n",
        "    # Fit the classifier on the training data\n",
        "    knn_classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Predict the labels for the test data\n",
        "    y_pred = knn_classifier.predict(X_test)\n",
        "\n",
        "    # Evaluate the accuracy\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    # Display the results\n",
        "    print(f\"\\nResults for k = {k} (Chebyshev metric):\")\n",
        "    print(f\"Predicted Labels: {y_pred}\")\n",
        "    print(f\"True Labels     : {y_test.values}\")\n",
        "    print(f\"Accuracy: {accuracy:.2%}\")\n",
        "    print(f\"Error   : {1 - accuracy:.2%}\")"
      ],
      "metadata": {
        "id": "R8O-GcrLfRaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Using k-NN classifiers for k = 1, 3, 5 with Jaccard metric"
      ],
      "metadata": {
        "id": "YHCcoKTMfSEF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize k-NN classifiers for k = 1, 3 and 5 with Jaccard metric\n",
        "for k in [1, 3, 5]:\n",
        "    knn_classifier = KNeighborsClassifier(n_neighbors=k, metric='jaccard', algorithm='auto')\n",
        "\n",
        "    # Fit the classifier on the training data\n",
        "    knn_classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Predict the labels for the test data\n",
        "    y_pred = knn_classifier.predict(X_test)\n",
        "\n",
        "    # Evaluate the accuracy\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    # Display the results\n",
        "    print(f\"\\nResults for k = {k} (Jaccard metric):\")\n",
        "    print(f\"Predicted Labels: {y_pred}\")\n",
        "    print(f\"True Labels     : {y_test.values}\")\n",
        "    print(f\"Accuracy: {accuracy:.2%}\")\n",
        "    print(f\"Error   : {1 - accuracy:.2%}\")"
      ],
      "metadata": {
        "id": "BMr_E-CwfSgY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}